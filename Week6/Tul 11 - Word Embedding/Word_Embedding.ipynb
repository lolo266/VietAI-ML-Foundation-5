{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>WORD EMBEDDING VÀ ỨNG DỤNG</center>\n",
    "\n",
    "\n",
    "*Word Embedding là một cách biểu diễn dữ liệu văn bản thành các vector, sao cho những vectors gần giống nhau sẽ biểu thị những từ với ý nghĩa gần giống nhau. Trong bài thực hành ngày hôm nay, chúng ta sẽ cùng làm quen và sử dụng các model Word Embedding có sẵn (pretrained model) để giải quyết các bài toán Machine Learning đơn giản* \n",
    "\n",
    "### Nội dung \n",
    "\n",
    "1 - Giới thiệu \n",
    "\n",
    "2 - Biểu diễn Word Embedding\n",
    "\n",
    "3 - Sử dụng Pretrained Word Embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Giới thiệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Pretrained model\n",
    "\n",
    "Các model Word Embedding được huấn luyện dựa trên tập dữ liệu rất lớn và đa dạng (dữ liệu từ Wikipedia), vì vậy thông thường khi cần sử dụng Word Embedding, ta sẽ sử dụng lại các model đã được huấn luyện sẵn. Một số pretrained model thường được sử dụng:\n",
    "- <a href = \"https://code.google.com/archive/p/word2vec/\" > Word2Vec </a>\n",
    "- <a href = \"https://nlp.stanford.edu/projects/glove/\" > GLoVe </a>\n",
    "- [BERT](https://github.com/google-research/bert)\n",
    "\n",
    "Các thông số cần lưu ý khi lựa chọn pretrained model:\n",
    "- Kích thước tập từ vựng (vocab)\n",
    "- Số chiều của vector biểu diễn từ (dimension)\n",
    "\n",
    "Trong tutorial này, chúng ta sẽ sử dụng word embedding cho tiếng Anh (en) và tiếng Việt (vi) đã được huấn luyện trước bằng mô hình Word2Vec. Cụ thể, các bạn tải 2 mô hình dưới đây và giải nén vào thư mục `./data`:\n",
    "1. en: https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki-news-300d-1M.vec.zip: cung cấp bởi [fasttext.cc](https://fasttext.cc/docs/en/english-vectors.html). Kích thước vocab: 1M, dimension: 300.\n",
    "2. vi: https://drive.google.com/open?id=0B0ZXk88koS2KUHZZZkVwd1RoVmc: cung cấp bởi [Kyubyong](https://github.com/Kyubyong/wordvectors). Kích thước vocab: 10K, dimension: 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Thư viện gensim\n",
    "Gensim là một thư viện trên Python được sử dụng cho các bài toán xử lý và phân tích dữ liệu văn bản. Trong bài thực hành này, chúng ta sẽ sử dụng thư viện Gensim để đọc và biểu diễn các từ và vector trong Word Embedding.\n",
    "\n",
    "Để cài đặt thư viện Gensim trên Anaconda, ta sử dụng lệnh\n",
    "\n",
    "```\n",
    "$ conda install -c anaconda gensim\n",
    "```\n",
    "\n",
    "Gensim cung cấp các module khác nhau để làm việc với Word Embedding, tùy thuộc vào loại model (W2V, Glove, etc.) và mục đích sử dụng (tiếp tục train hay không), mà ta có thể lựa chọn module phù hợp. Chi tiết về các module của gensim có thể đọc tại <a href = \"https://radimrehurek.com/gensim/models/word2vec.html\"> Gensim Word2Vec </a> và <a href = \"https://radimrehurek.com/gensim/models/keyedvectors.html\"> Gensim KeyedWordVectors </a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Biểu diễn Word Embedding\n",
    "Sử dụng thư viện Gensim để load dữ liệu từ pretrained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "en_vectors = KeyedVectors.load_word2vec_format('data/wiki-news-300d-1M.vec', binary=False)\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "vi_vectors = Word2Vec.load('data/vi.bin').wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Lưu ý: đối với model glove, cần chuyển về format word2vec\n",
    "# # Ví dụ\n",
    "# from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "# glove2word2vec('data/glove.6B.50d.txt', 'data/en.vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KeyedVectors object có dạng là một từ điển chứa các từ và vector tương ứng với từ đó. Ta có thể truy xuất tập từ vựng (vocab) của model cũng như giá trị vector của từ như sau: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector size:  300\n",
      "vocab size:  999994\n"
     ]
    }
   ],
   "source": [
    "en_vectors.vocab\n",
    "\n",
    "en_vectors[\"cat\"]\n",
    "\n",
    "print (\"vector size: \", en_vectors.vector_size)\n",
    "print (\"vocab size: \", len(en_vectors.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector size:  100\n",
      "vocab size:  10087\n"
     ]
    }
   ],
   "source": [
    "print (\"vector size: \", vi_vectors.vector_size)\n",
    "print (\"vocab size: \", len(vi_vectors.vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Độ tương đồng\n",
    "Giá trị cosine similarity giữa các vector biểu diễn từ trong Word Embedding cho biết mức độ tương đồng giữa các từ. Mức độ tương đồng này có thể phản ánh về mặt ý nghĩa hoặc chức năng ngữ pháp của từ trong câu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cats', 0.855280876159668),\n",
       " ('feline', 0.7388774752616882),\n",
       " ('kitten', 0.7353649139404297),\n",
       " ('Cat', 0.7278350591659546),\n",
       " ('felines', 0.6910911798477173),\n",
       " ('scaredy', 0.6898840665817261),\n",
       " ('dog', 0.6873316764831543),\n",
       " ('kitty', 0.6711601614952087),\n",
       " ('moggy', 0.6699495315551758),\n",
       " ('meow', 0.6599326133728027)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vectors.most_similar(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ngỗng', 0.7897291779518127),\n",
       " ('sói', 0.7704877853393555),\n",
       " ('nhện', 0.7638152241706848),\n",
       " ('ếch', 0.7570170760154724),\n",
       " ('cá_voi', 0.7384120225906372),\n",
       " ('chó_sói', 0.7315294742584229),\n",
       " ('cá_heo', 0.7314594984054565),\n",
       " ('cá_vàng', 0.7240824103355408),\n",
       " ('cá_chép', 0.7233684659004211),\n",
       " ('khỉ', 0.7190860509872437)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi_vectors.most_similar(\"mèo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Mối quan hệ về không gian giữa các từ\n",
    "Một tính chất thú vị của Word Embedding là ngoài việc thể hiện độ tương đồng giữa các từ đơn lẽ, trong không gian vector từ của Word Embedding vị trí tương đối giữa các cặp từ có mối quan hệ tương đồng về ngữ nghĩa sẽ có khoảng cách tương đối giống nhau.\n",
    "\n",
    "![title](image/word2vec-gender-relation.png)\n",
    "\n",
    "![Mối quan hệ về ngữ pháp: số ít - số nhiều](image/word2vec-plural-relation.png)\n",
    "\n",
    "Mối quan hệ này được biểu diễn qua một phương trình đơn giản:\n",
    "```\n",
    "vector('king') - vector('queen') = vector('man') - vector(woman)\n",
    "vector('king') - vector('kings') = vector('queen') - vector(queens)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queen is a:  woman\n",
      "Plural form of `queen` is :  queens\n"
     ]
    }
   ],
   "source": [
    "sim_words = en_vectors.most_similar(positive=['queen', 'man'], negative=['king'])\n",
    "print('Queen is a: ', sim_words[0][0])\n",
    "\n",
    "sim_words = en_vectors.most_similar(negative=['king'], positive=['kings', 'queen'])\n",
    "print('Plural form of `queen` is : ', sim_words[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Biểu diễn Word Embedding trên không gian 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để biểu diễn một cách trực quan kết quả của mô hình Word Embedding, ta sử dụng giải thuật T-SNE , giúp làm giảm số chiều của vector đặc trưng từ mà vẫn giữ được mối quan hệ tương đối giữa các từ. \n",
    "\n",
    "Trong mục này, các bạn nên cài đặt thêm thư viện `MulticoreTSNE` để tăng tốc độ giải thuật T-SNE, hoặc dùng module sẵn có trong thư viện `scikit-learn` (xem thêm bên dưới) nhưng sẽ chậm hơn tương đối nhiều."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting MulticoreTSNE\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7f6f5c6efcf8>: Failed to establish a new connection: [Errno -2] Name or service not known')': /simple/multicoretsne/\u001b[0m\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7f6f5c6fa438>: Failed to establish a new connection: [Errno -2] Name or service not known')': /simple/multicoretsne/\u001b[0m\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7f6f5c6faba8>: Failed to establish a new connection: [Errno -2] Name or service not known')': /simple/multicoretsne/\u001b[0m\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7f6f5c6fa0f0>: Failed to establish a new connection: [Errno -2] Name or service not known')': /simple/multicoretsne/\u001b[0m\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7f6f5c6fab00>: Failed to establish a new connection: [Errno -2] Name or service not known')': /simple/multicoretsne/\u001b[0m\n",
      "\u001b[31m  ERROR: Could not find a version that satisfies the requirement MulticoreTSNE (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for MulticoreTSNE\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install MulticoreTSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_sub_embedding(word_vectors, vocabs):\n",
    "    \n",
    "    sub_embeddings = []\n",
    "    for word in vocabs:\n",
    "        if word in word_vectors:\n",
    "            sub_embeddings.append(word_vectors[word])\n",
    "        else:\n",
    "            vocabs.remove(word)\n",
    "    return np.array(sub_embeddings), vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/10000_common_words.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0a34ca73c0db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Chỉ sử dụng 10000 từ thông dụng trong tiếng anh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# để train TSNE model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/10000_common_words.txt\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0men_vocabs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0men_vocabs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0men_vocabs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/10000_common_words.txt'"
     ]
    }
   ],
   "source": [
    "# Chỉ sử dụng 10000 từ thông dụng trong tiếng anh \n",
    "# để train TSNE model\n",
    "with open(\"data/10000_common_words.txt\") as f:\n",
    "    en_vocabs = f.read().splitlines() \n",
    "    en_vocabs = [word.strip() for word in en_vocabs]\n",
    "en_sub_embedding, en_vocabs = get_sub_embedding(en_vectors, en_vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi_vocabs = vi_vectors.vocab\n",
    "vi_sub_embedding, vi_vocabs = get_sub_embedding(vi_vectors, vi_vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "# # Có thể dùng class TSNE trong scikit-learn, nhưng sẽ chậm hơn\n",
    "# from sklearn.manifold import TSNE\n",
    "np.random.seed(2018)\n",
    "\n",
    "def get_2D_vector(vectors):\n",
    "    \"\"\"\n",
    "        Sử dụng giải thuật TSNE để ánh xạ vectors nhiều chiều về 2 chiều\n",
    "        http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html\n",
    "        https://distill.pub/2016/misread-tsne/\n",
    "    \"\"\"\n",
    "    tsne = TSNE(perplexity=25, n_components=2, init='random', n_iter=1000, n_jobs=-1)\n",
    "    return tsne.fit_transform(vectors)\n",
    "\n",
    "en_vector_2D = get_2D_vector(en_sub_embedding)\n",
    "vi_vector_2D = get_2D_vector(vi_sub_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pylab, rcParams\n",
    "import random\n",
    "\n",
    "def plot(embeddings, labels, drawn_vocabs):\n",
    "    \"\"\"\n",
    "        Sử dụng thư viện matplotlib để biểu diễn từ lên mặt phẳng tọa độ\n",
    "    \"\"\"\n",
    "    pylab.figure(figsize=(50,50)) \n",
    "    rcParams.update({'font.size': 40}) \n",
    "    for i, label in enumerate(labels):\n",
    "        if label in drawn_vocabs:\n",
    "            x, y = embeddings[i,:]\n",
    "            pylab.scatter(x, y)\n",
    "            xt = random.randint(0,200)\n",
    "            yt = random.randint(0,200)\n",
    "            pylab.annotate(label, xy=(x, y), xytext=(xt, yt), textcoords='offset points',\n",
    "                       ha='right', va='bottom')\n",
    "    pylab.show()\n",
    "    \n",
    "en_drawn_vocabs = [\"cat\", \"dog\", \"bird\", \"mouse\",\n",
    "                \"woman\", \"man\", \"women\", \"men\", \"girl\", \"boy\",\n",
    "                \"student\", \"teacher\", \"doctor\",\n",
    "                \"one\", \"two\", \"three\", \"four\", \"five\",\n",
    "                \"play\", \"jump\", \"go\",\n",
    "                \"monday\", \"tuesday\", \"wednesday\", \"sunday\",\n",
    "                \"usa\", \"uk\", \"canada\", \"china\", \"vietnam\"]\n",
    "plot(en_vector_2D, en_vocabs, en_drawn_vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi_drawn_vocabs = [\"mèo\", \"chó\", \"chim\", \"chuột\",\n",
    "                \"phụ_nữ\", \"đàn_ông\", \"đàn_bà\", \"trai\", \"con_trai\", \"gái\", \"con_gái\",\n",
    "                \"học_sinh\", \"giáo_viên\", \"thầy_giáo\", \"cô_giáo\", \"bác_sĩ\",\n",
    "                \"một\", \"hai\", \"ba\", \"bốn\", \"năm\",\n",
    "                \"chơi\", \"nhảy\", \"chạy\",\n",
    "                \"thứ_hai\", \"thứ_ba\", \"thứ_tư\", \"thứ_năm\",\n",
    "                \"mỹ\", \"anh\", \"canada\", \"trung_quốc\", \"việt_nam\"]\n",
    "plot(vi_vector_2D, vi_vocabs, vi_drawn_vocabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sử dụng Pretrained Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretrained Word Embedding được biểu diễn như một ma trận trọng số (W) trong Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def create_embedding_matrix(word_vectors):\n",
    "    \"\"\"\n",
    "        Chuyển KeyedVectors về ma trận embedding\n",
    "        và từ điển chứa các cặp word - index\n",
    "\n",
    "        @param      word_vectors        Dữ liệu word embedding lưu dưới định dạng KeyedVectors\n",
    "        @return     embedding_matrix    ma trận word embedding với shape = (num_words,embedding_dim)\n",
    "                    word2index          từ điển chứa cặp word - index\n",
    "                    num_words           kích thước tập từ vựng\n",
    "                    embedding_dim       số chiều vector embedding\n",
    "                    \n",
    "    \"\"\"\n",
    "\n",
    "    # --------------- TODO ---------------------------\n",
    "    \n",
    "\n",
    "\n",
    "    # ------------------------------------------------\n",
    "\n",
    "    return embedding_matrix, word2index, num_words, embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ma trận embedding được sử dụng để chuyển đổi các từ thành vector\n",
    "embedding_matrix, word2index, num_words, embedding_dim = create_embedding_matrix(en_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "def to_index(sentence, word2index):\n",
    "    \"\"\"\n",
    "        Chuyển câu thành index vector\n",
    "        @param      sentence       câu\n",
    "        @param      word2index     từ điển chứa cặp word - index\n",
    "\n",
    "        e.g: \"hello world\" => [0, 1]\n",
    "    \"\"\"\n",
    "\n",
    "    sentence = nltk.word_tokenize(sentence)\n",
    "    index_vector = None\n",
    "    # --------------- TODO ---------------------------\n",
    "\n",
    "   \n",
    "\n",
    "    # ------------------------------------------------\n",
    "\n",
    "    return index_vector\n",
    "\n",
    "def to_embedding_vectors(sentence, word2index, embedding_matrix):\n",
    "    \"\"\"\n",
    "        Chuyển câu thành ma trận của các embedding vector\n",
    "        @param      sentence       câu\n",
    "        @param      word2index     từ điển chứa cặp word - index\n",
    "\n",
    "        e.g: \"hello world\" => [0, 1] => [[00..00], [00..01]]\n",
    "    \"\"\"\n",
    "\n",
    "    # --------------- TODO ---------------------------\n",
    "    \n",
    "   \n",
    "\n",
    "    # ------------------------------------------------\n",
    "\n",
    "    return embedding_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"this is an example\"\n",
    "index_vector = to_index(sentence, word2index)\n",
    "embedding_vector = to_embedding_vectors(sentence, word2index, embedding_matrix)\n",
    "print (embedding_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để sử dụng Word Embedding trên Tensorflow, tham khảo <a href = \"https://www.tensorflow.org/api_docs/python/tf/nn/embedding_lookup\" > Embedding Lookup </a>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.3",
    "jupytext_version": "0.8.6"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
